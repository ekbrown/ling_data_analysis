dfm(tokens(data_corpus_inaugural))
data_corpus_inaugural
tokens(data_corpus_inaugural)
dfm(tokens(data_corpus_inaugural))
dfmat1 <- dfm(tokens(data_corpus_inaugural)) %>% dfm_group(groups = period))
dfmat1 <- dfm(tokens(data_corpus_inaugural)) %>% dfm_group(groups = period)
head(dfmat1) # make sure 'post-war' is in the first row
data_corpus_inaugural
docvars(data_corpus_inaugural)
period <- ifelse(docvars(data_corpus_inaugural, "Year") < 1945, "pre-war", "post-war")
period
dfm(tokens(data_corpus_inaugural))
dfmat1 <- dfm(tokens(data_corpus_inaugural)) %>% dfm_group(groups = period)
head(dfmat1) # make sure 'post-war' is in the first row
?textstat_keyness
library(rves)
library(rvest)
page <- read_html("https://eur-lex.europa.eu/legal-content/ES/TXT/HTML/?uri=CELEX:12016M/TXT")
page %>%
html_text2()
page %>%
html_text2() %>%
write_lines(file = "/Users/ekb5/Downloads/eu_leyes.txt")
2709/3
sessionInfo()
10^-15.005441665649414
install.packages("nycflights13")
library("nycflights13")
flights
flights %>% view
library(tidyverse)
flights %>% view
flights
1301/60
60*24
library(nycflights13)
flights
flights %>% view
library(tidyverse)
flights %>% view
library(nycflights13)
names(flights)
library(tidyverse)
?select
library("nycflights13")
flights
flights |>
summarize(mean(dep_delay))
library("tidyverse")
flights |>
summarize(mean(dep_delay))
clear()
flights |>
filter(!is.na(dep_delay)) |>
group_by(carrier) |>
summarize(mean(dep_delay))
library(nycflights13)
flights |> names
flights |> names()
library("readxl")
library("tidyverse")
setwd("/Users/ekb5/Documents/data_analysis/datasets/")
sibilants <- read_excel("data_FRC_spch_rate.xlsx", sheet = "data")
sibilants
sibilants |> pull(spch_rate)
?left_join
?separate
?unite
x <- "Bobby: I'm hungry!"
str_extract(x, "^.*?:")
str_extract(x, "^.*?(?!:)")
str_extract(x, ".*?(?!:)")
str_extract(x, ".*?")
str_extract(x, "^.*?")
str_extract(x, "^.*")
str_extract(x, "^[^:]+")
str_extract(x, "[^:]+4")
str_extract(x, "[^:]+$")
?unite
0.6436^4
0.3564 + 0.3564 - (0.3564 * 0.3564)
library("readxl")
library("tidyverse")
setwd("/Users/ekb5/Downloads/")
sibilants <- read_excel("data_L2s.xlsx", sheet = "data_hls_2017-10-25")
sibilants
?pivot_longer
library("tidyverse")
?pivot_longer
?tribble
library(tidyverse)
?pivot_wider
#| eval: true
library("tidyverse")
library("readxl")
rpm <- read_excel("/Users/ekb5/Documents/data_analysis/datasets/RPM_2019_for_Reliability.xlsx", sheet = "For Earl")
rpm |>
pivot_wider(names_from = "Page/Item", values_from = "Correct/incorrect")
library(readxl)
?readxl
?readxl()
rpm
tail(rpm)
rpm <- read_excel("/Users/ekb5/Documents/data_analysis/datasets/RPM_2019_for_Reliability.xlsx", sheet = "For Earl", range = "For Earl!A1:E3745")
rpm <- read_excel("/Users/ekb5/Documents/data_analysis/datasets/RPM_2019_for_Reliability.xlsx", range = "For Earl!A1:E3745")
rpm
tail(rpm)
rpm <- read_excel("/Users/ekb5/Documents/data_analysis/datasets/RPM_2019_for_Reliability.xlsx", range = "For Earl!A1:E3745")
rpm |>
pivot_wider(names_from = "Page/Item", values_from = "Correct/incorrect")
rpm
rpm |>
pivot_wider(names_from = "Page/Item", values_from = "Correct/incorrect")
?rep
rep(1:104, times = 36)
rep(1:104, length.out = 36)
rep_len(1:104, length.out = 36)
rep(1:104, each. = 36)
rep(1:104, each = 36)
rpm |>
mutate(id = rep(1:104, each = 36)) |>
pivot_wider(names_from = "Page/Item", values_from = "Correct/incorrect")
rpm |>
mutate(id = rep(1:104, each = 36)) |>
pivot_wider(names_from = "Page/Item", values_from = "Correct/incorrect") |>
relocate(id, .before = 1)
rpm |>
mutate(id = rep(1:104, each = 36)) |>
pivot_wider(names_from = "Page/Item", values_from = "Correct/incorrect") |>
relocate(id, .before = 1) |> view()
library(tidyverse)
library(joeystanley)
install.packages(joeystanley)
install.packages('joeystanley')
f <- factor(c("a", "b", "c", "d"), levels = c("b", "c", "d", "a"))
levels(f)
?pivot_wider
?pivot_longer
vowels
library(tidyverse)
?geom_mosaic
??geom_mosaic
q1=1970342.3066
q3=2135475.4842
iqr=q3-q1
iqr
q1
q3
q3+(1.5*iqr)
0.86^2
36.6/40
install.packages("ggmosaic")
#| eval: false
library("tidyverse")
library("readxl")
ptk <- read_excel("../../../data_analysis/datasets/Data_ptk.xlsx", sheet = "data")
glimpse(ptk)
head(ptk)
# install.packages("devtools")
devtools::install_github("haleyjeppson/ggmosaic")
install.packages("devtools")
# install.packages("devtools")
devtools::install_github("haleyjeppson/ggmosaic")
ptk
ptk |> ggplot(aes(x = LANG, fill = GENRE))+geom_mosaic()
library("ggmosaic")
ptk |> ggplot(aes(x = LANG, fill = GENRE))+geom_mosaic()
ptk |> ggplot()+geom_mosaic(aes(x = LANG, fill = GENRE))
ptk |> ggplot()+geom_mosaic(aes(x = LANG, fill = prePhonBin))
#| eval: false
ptk |>
ggplot(aes(x = LANG, fill=prePhonBin))+
geom_bar(position = "fill")
ptk |>
ggplot(aes(x = LANG, fill=prePhonBin))+
geom_bar(position = "fill")
ptk |> ggplot()+geom_mosaic(aes(x = LANG, fill = prePhonBin))
ptk |> ggplot()+geom_mosaic(aes(x = GENRE, fill = prePhonBin))
ptk |> ggplot()+geom_mosaic(aes(x = prePhonBin, fill = LANG))
ptk |> ggplot()+geom_mosaic(aes(x = prePhonBin, fill = LANG))
#| eval: false
library("tidyverse")
library("readxl")
ptk <- read_excel("../../../data_analysis/datasets/Data_ptk.xlsx", sheet = "data")
glimpse(ptk)
head(ptk)
ptk |>
ggplot()+
geom_mosaic(aes(x = prePhonBin, fill = LANG))
library("ggmosaic")
ptk |>
ggplot()+
geom_mosaic(aes(x = prePhonBin, fill = LANG))
ptk |>
ggplot()+
geom_mosaic(aes(x = prePhonBin, fill = LANG))
ptk |>
ggplot()+
geom_mosaic(aes(x = prePhonBin, fill = LANG))
ptk |> pull(prePhonBin)
ptk |>
ggplot(aes(x = prePhonBin, fill = LANG))+
geom_mosaic()
ptk %>%
ggplot(aes(x = prePhonBin, fill = LANG))+
geom_mosaic()
library("tidyverse")
ptk %>%
ggplot(mapping = aes(x = prePhonBin, fill = LANG))+
geom_mosaic()
ptk %>%
ggplot()+
geom_mosaic(mapping = aes(x = prePhonBin, fill = LANG))
library("ggmosaic")
# ptk |>
#   ggplot()+
#   geom_mosaic(aes(x = prePhonBin, fill = LANG))
ptk %>%
ggplot()+
geom_mosaic(mapping = aes(x = prePhonBin, fill = LANG))
see.m <- c(44,48,27,17)
see.nm <- c(26,135,98,19)
rbind(see.m, see.nm)
temp <- ptk |>
count(prePhonBin, LANG) |>
pivot_wider(names_from = LANG, values_from = n)
temp
temp |> data.matrix()
row_names
temp <- ptk |>
count(prePhonBin, LANG) |>
pivot_wider(names_from = LANG, values_from = n)
row_names <- temp |> pull(1)
temp |> data.matrix()[,2:3]
temp <- ptk |>
count(prePhonBin, LANG) |>
pivot_wider(names_from = LANG, values_from = n)
row_names <- temp |> pull(1)
temp %>% data.matrix()[,2:3]
temp
row_names
temp_m <- temp |> data.matrix()
temp_m
temp_m[,-1]
temp |> data.matrix()[,-1)
temp |> data.matrix()[,-1]
temp_m[,-1]
#| eval: true
install.packages("devtools")
devtools::install_github("joeystanley/joeysvowels")
install.packages("devtools")
#| eval: true
library("tidyverse")
midpoints <- joeysvowels::coronals
glimpse(midpoints)
head(midpoints)
midpoints <- midpoints|>
filter(percent == 50)  |>
select(-percent) |>
filter(!vowel %in% c("PRICE", "MOUTH", "CHOICE"))
midpoints |>
ggplot(aes(x = F2, y = F1))+
geom_point()
96/3
library(tidyverse)
?stat_summary
?ggproto
library(tidyverse)
?geom_jitter
?geom_rug
library(tidyverse)
?stat_ellipse
?theme_bw
?element_text
248/64
4113-3347
3833-3347
4113-3833
library("rvest")
library("tidyverse")
read_html("https://eur-lex.europa.eu/eli/reg/2024/792/oj") |>
html_element(css = ".eli-container") |>
html_text2() |>
write_lines(file = "/Users/ekb5/Downloads/reg.txt")
read_html("/Users/ekb5/Downloads/Search%20results%2020240304.xml")
read_html("/Users/ekb5/Downloads/Search results 20240304.xml")
read_html("/Users/ekb5/Downloads/Search results 20240304.xml") |>
xml_nodes(xpath = "//RESOURCE_LEGAL_ELI/VALUE")
read_html("/Users/ekb5/Downloads/Search results 20240304.xml") |>
html_nodes(xpath = "//RESOURCE_LEGAL_ELI/VALUE")
read_html("/Users/ekb5/Downloads/Search results 20240304.xml") |>
html_nodes(xpath = "\\RESOURCE_LEGAL_ELI\VALUE")
read_html("/Users/ekb5/Downloads/Search results 20240304.xml") |>
html_nodes(xpath = "//RESOURCE_LEGAL_ELI/VALUE")
read_html("/Users/ekb5/Downloads/Search results 20240304.xml")
read_html("/Users/ekb5/Downloads/Search results 20240304.xml") |>
html_nodes(css = "RESOURCE_LEGAL_ELI/VALUE")
read_html("/Users/ekb5/Downloads/Search results 20240304.xml") |>
html_nodes(css = "VALUE")
library("xml2")
read_xml("/Users/ekb5/Downloads/Search results 20240304.xml") |>
html_nodes(css = "VALUE")
read_xml("/Users/ekb5/Downloads/Search results 20240304.xml")
VALUE
read_xml("/Users/ekb5/Downloads/Search results 20240304.xml") |>
xml_find_all(xpath = "//VALUE")
read_xml("/Users/ekb5/Downloads/Search results 20240304.xml") |>
xml_find_all(xpath = "//result")
read_xml("/Users/ekb5/Downloads/Search results 20240304.xml")
?xml_find_all
read_xml("/Users/ekb5/Downloads/Search results 20240304.xml") |>
xml_find_all(xpath = "\\VALUE")
read_xml("/Users/ekb5/Downloads/Search results 20240304.xml") |>
xml_find_all(xpath = "//VALUE")
read_xml("/Users/ekb5/Downloads/Search results 20240304.xml") |>
xml_find_all(xpath = "http://eur-lex.europa.eu/search//VALUE")
read_xml("/Users/ekb5/Downloads/Search results 20240304.xml") |>
xml_find_all(xpath = "//http://eur-lex.europa.eu/search:VALUE")
read_xml("/Users/ekb5/Downloads/Search results 20240304.xml") |>
xml_find_all(xpath = "//xsi:VALUE")
install.packages("reticulate")
install.packages("reticulate")
sample(split("Ca Ky Da No Py Au Ja Sa", " "))
library("tidyverse")
sample(str_split("Ca Ky Da No Py Au Ja Sa", " "))
sample(str_split("Ca Ky Da No Py Au Ja Sa", " ")[[1]])
sample(str_split("Ca Ky Da No Py Au Ja Sa", " ")[[1]], size = 1)
# R code here
library("reticulate")
use_python("/usr/local/bin/python3")
txt <- "The quick brown fox jumped over the lazy dog."
nltk <- import("nltk")
tokens <- nltk$word_tokenize(txt)
print(tokens)
tagged <- nltk$pos_tag(tokens)
print(tagged)
for (tag in tagged) {
if (tag[2] == "NN") {
print(tag[1])
}
}
log7
log(7)
tibble(x, y) |>
bindrows(x = 59, y = 3.2) |>
```
y <- x * 3.1415926
jitter(3)
jitter(3)
jitter(3)
jitter(3)
jitter(3)
jitter(3)
25.6-2*17.8
25.6+2*17.8
library(tidyverse)
?map
baby_heights <- c(21, 19, 20, 18, 20, 73, 22, 18, 19)
map_dbl(baby_heights, scale)
scale(baby_heights)
?scale
mean(baby_heights)
sd(baby_heights)
as.vector(scale(baby_heights))
?quartile
?quantile
.2453*.35
library("reticulate")
num2words <- import("num2words")
use_python("/usr/local/bin/python3")
num2words <- import("num2words")
num2words$num2words(42)
num2words$num2words(42, lang="es")
num2words$num2words(42, lang="da")
num2words$num2words(42, lang="fr")
nltk <- import("nltk")
txt = "The quick brown fox jumped over the lazy dog."
nltk$word_tokenize()
tokens <- nltk$word_tokenize()
print(tokens)
nltk <- import("nltk")
txt = "The quick brown fox jumped over the lazy dog."
tokens <- nltk$word_tokenize()
print(tokens)
tokens <- nltk$word_tokenize(txt)
print(tokens)
library("Rcpp")
cppFunction('int add(int x, int y, int z) {
int sum = x + y + z;
return sum;
}')
add(1, 2, 3)
add(1, 2, 3)
add(1, 2, 3)
add(1, 2, 3)
add(1, 2, 3)
add(1, 2, 3)
library("tidyverse")
baby_heights <- c(21, 19, 20, 18, 20, 73, 22, 18, 19)
tibble(baby_heights) |>
summarize(mean(baby_heights), sd(baby_heights))
scale(baby_heights)
tibble(baby_heights)
baby_heights
tibble(baby_heights)
tibble(baby_heights) |>
mutate(z_height = as.vector(scale(baby_heights)))
tibble(baby_heights) |>
mutate(z_height = as.vector(scale(baby_heights))) |>
filter(z_height > -2 & z_height < 2)
tibble(baby_heights)
tibble(baby_heights) |>
pull(baby_heights)
tibble(baby_heights) |>
pull(baby_heights) |>
quantile(probs = c(0.25, 0.75))
tibble(baby_heights) |>
pull(baby_heights) |>
quantile(probs = c(0.25, 0.75, 0.95))
quartiles <- tibble(baby_heights) |>
pull(baby_heights) |>
quantile(probs = c(0.25, 0.75))
quartiles
quartiles[1]
q1 <- quartiles[1]
quartiles[2]
q3 <- quartiles[2]
iqr <- q3 - q1
quartiles <- tibble(baby_heights) |>
pull(baby_heights) |>
quantile(probs = c(0.25, 0.75))
q1 <- quartiles[1]
q3 <- quartiles[2]
iqr <- q3 - q1
# here we go with the actual filtering
tibble(baby_heights) |>
filter(
baby_heights > q1 - 1.5 * iqr &
baby_heights < q3 + 1.5 * iqr)
library("tidyverse")
library("readxl")
ptk <- read_excel("C:/Users/ekb5.BYU/Downloads/Data_ptk.xlsx", sheet = "data")
# get the number of rows and columns
ptk |> dim() # rows, columns
ptk <- read_excel("/Users/ekb5/Documents/data_analysis/datasets/Data_ptk.xlsx", sheet = "data")
# get the number of rows and columns
ptk |> dim() # rows, columns
# filter outliers below or above two standard deviations from the mean and then get the number of rows and columns again
ptk |>
mutate(VOT_z = as.vector(scale(VOT))) |>
filter(VOT_z > -2 & VOT_z < 2) |>
dim()
ptk <- read_excel("/Users/ekb5/Documents/data_analysis/datasets/Data_ptk.xlsx", sheet = "data")
# get the number of rows and columns
ptk |> dim() # rows, columns
# filter outliers below or above two standard deviations from the mean and then get the number of rows and columns again
ptk |>
mutate(VOT_z = as.vector(scale(VOT))) |>
filter(VOT_z > -2 & VOT_z < 2) |>
dim()
1578-1512
300/89^.5
75/sqrt(100)
?t.test
library(rvest)
library(tidyverse)
library(rvest)
read_html("/Users/ekb5/Downloads/Slate Reader.html")
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table")
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[1]
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[1] %>%
html_table()
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[2] %>%
html_table()
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[3] %>%
html_table()
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[4] %>%
html_table()
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[4] %>%
html_table() %>%
write_csv(file = "/Users/ekb5/Downloads/applicants.csv")
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[[4]] %>%
html_table() %>%
write_csv(file = "/Users/ekb5/Downloads/applicants.csv")
0.5357*.6
70-67.5
70-1.25
install.packages("languageR")
languageR::english
languageR::english %>% as_tibble()
library("tidyverse")
languageR::english %>% as_tibble()
?languageR::english
languageR::english %>% count(Word)
languageR::english %>% filter(Word == "drone")
install.packages("Rling")
mean(c(823,788,754))
