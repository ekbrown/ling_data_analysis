read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[1] %>%
html_table()
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[2] %>%
html_table()
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[3] %>%
html_table()
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[4] %>%
html_table()
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[4] %>%
html_table() %>%
write_csv(file = "/Users/ekb5/Downloads/applicants.csv")
read_html("/Users/ekb5/Downloads/Slate Reader.html") %>%
html_elements("table") %>%
.[[4]] %>%
html_table() %>%
write_csv(file = "/Users/ekb5/Downloads/applicants.csv")
0.5357*.6
70-67.5
70-1.25
install.packages("languageR")
languageR::english
languageR::english %>% as_tibble()
library("tidyverse")
languageR::english %>% as_tibble()
?languageR::english
languageR::english %>% count(Word)
languageR::english %>% filter(Word == "drone")
install.packages("Rling")
mean(c(823,788,754))
oldmen <- sample(20:30, 50, replace=T)
oldmen
plot(oldmen)
hist(oldmen)
oldwomen <- sample(10:20, 50, T)
oldwomen
oldmen <- sample(20:30, 50, replace=T)
oldwomen <- sample(10:20, 50, T)
youngmen <- sample(10:20, 50, T)
youngwomen <- sample(10:20, 50, T)
tibble(oldmen, oldwomen, youngmen, youngwomen)
library(tidyverse)
tibble(oldmen, oldwomen, youngmen, youngwomen)
tibble(oldmen, oldwomen, youngmen, youngwomen) %>%
pivot_longer(cols = everything(), names_to = group, values_to = n)
tibble(oldmen, oldwomen, youngmen, youngwomen) %>%
pivot_longer(cols = everything(), names_to = "group", values_to = "n")
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
tibble(old_men, old_women, young_men, young_women) %>%
pivot_longer(cols = everything(), names_to = "group", values_to = "n") %>%
separate(col = group, into = c("age", "sex"), sep = "_")
tibble(old_men, old_women, young_men, young_women) %>%
pivot_longer(cols = everything(), names_to = "group", values_to = "n") %>%
separate(col = group, into = c("age", "sex"), sep = "_") %>%
ggplot(aes(sex, n))+
geom_boxplot()+
facet_wrap(~age)
tibble(old_men, old_women, young_men, young_women) %>%
pivot_longer(cols = everything(), names_to = "group", values_to = "n") %>%
separate(col = group, into = c("age", "sex"), sep = "_") %>%
ggplot(aes(sex, n))+
geom_boxplot(notch = T)+
facet_wrap(~age)
tibble(old_men, old_women, young_men, young_women) %>%
pivot_longer(cols = everything(), names_to = "group", values_to = "n") %>%
separate(col = group, into = c("age", "sex"), sep = "_") %>%
ggplot(aes(sex, n))+
geom_boxplot(notch = T)+
facet_wrap(~age)+
stat_summary(fun = mean)
tibble(old_men, old_women, young_men, young_women) %>%
pivot_longer(cols = everything(), names_to = "group", values_to = "n") %>%
separate(col = group, into = c("age", "sex"), sep = "_") %>%
ggplot(aes(sex, n))+
geom_boxplot(notch = T)+
facet_wrap(~age)+
stat_summary(fun = mean)+
theme_bw()
tibble(old_men, old_women, young_men, young_women) %>%
pivot_longer(cols = everything(), names_to = "group", values_to = "n") %>%
separate(col = group, into = c("age", "sex"), sep = "_") %>%
write_csv(file = "/Users/ekb5/Documents/LING_440/regionalisms.csv")
region
library("tidyverse")
region <- read_csv("/Users/ekb5/Documents/LING_440/regionalisms.csv")
region
region %>% view
?leveneTest
??leveneTest
.67*45
.67*45*2
20*.67
10*2*.67
45*2*.67
honor <- c(250, 250, 500, 500)
sum(honor)
6175-sum(honor)
library("rms")
install.packages("rms")
rms::doenLaten
data(doenLaten)
library(rms)
data(doenLaten)
library("Rling")
data(doenLaten)
?doenLaten
?gm
?glm
?glm
library(Rling)
data(ELP)
m1 <- lm(Mean_RT ~ Length + log(SUBTLWF) + POS, data = ELP)
m1
m2 <- glm(Mean_RT ~ Length + log(SUBTLWF) + POS, family = "gaussian", data = ELP)
m2
summary(m1)
summary(m2)
178/277
178+277
178/455
doenLaten %>% summary()
library(tidyverse)
doenLaten %>% summary()
levels(doenLaten$Aux)
exp(1.8631)
exp(.7085)
library(languageR)
data(diatones)
read_csv("https://github.com/msonderegger/rmld-v1.1/blob/main/data/diatones_rmld.csv")
diatones <- read_csv("/Users/ekb5/Documents/data_analysis/datasets/diatones_rmld.csv")
diatones
diatones
view(diatones)
rms::lrm(stress_shifted ~ prefix, data = diatones)
levels(diatones$prefix)
diatones
diatones <- read.csv("/Users/ekb5/Documents/data_analysis/datasets/diatones_rmld.csv", stringsAsFactors = TRUE)
diatones$prefix %>% levels()
rms::lrm(stress_shifted ~ frequency, data = diatones)
rms::lrm(stress_shifted ~ frequency + syll1_coda, data = diatones)
library(languageR)
data("regularity")
?regularity
regularity %>% view
levels(regularity$Regularity)
slope=40.838
y=40.838
slope=.417
y+slpe*67
y+slope*67
y
slope
y+slope*67
25000*10000
13*3
39/11
3.5*11
library("tidyverse")
library("rvest")
library("tidyverse")
library("rvest")
read_html("https://www.mturk.com/participation-agreement")
read_html("https://www.mturk.com/participation-agreement") %>%
html_element(".agreement")
read_html("https://www.mturk.com/participation-agreement") %>%
html_element(".agreement") %>%
html_text2()
amazon %>%
html_element(".agreement") %>%
html_text2() %>%
str_extract_all(regex("[-'’a-z]+"))
amazon <- read_html("https://www.mturk.com/participation-agreement")
amazon %>%
html_element(".agreement") %>%
html_text2() %>%
str_extract_all(regex("[-'’a-z]+"))
amazon %>%
html_element(".agreement") %>%
html_text2() %>%
str_extract_all(regex("[-'’a-z]+")) %>%
length()
amazon %>%
html_element(".agreement") %>%
html_text2() %>%
str_extract_all(regex("[-'’a-z]+")) %>%
unlist() %>%
length()
install.packages("readxl")
install.packages("readxl")
install.packages("Matrix")
m1
?update
install.packages("lmtest")
install.packages("lmtest")
library("tidyverse")
tibble(age = c(20, 18, 16, 14, 12), height = c(72, 70, 69, 63, 64))
kids <- tibble(age = c(20, 18, 16, 14, 12), height = c(72, 70, 69, 63, 64))
kids %>%
ggplot(aes(age, height))+
geom_point()
kids %>%
mutate(age2 = age - mean(age))
kids %>%
mutate(age2 = age - mean(age), height2 = height - mean(height))
kids %>%
mutate(age2 = age - mean(age), height2 = height - mean(height)) %>%
ggplot(aes(age2, height2))+
geom_point()
kids %>%
ggplot(aes(age3, height3))+
geom_point()
kids %>%
mutate(age2 = age - mean(age), height2 = height - mean(height)) %>%
mutate(age3 = scale(age), height3 = scale(height))
kids
kids <- kids %>%
mutate(age2 = age - mean(age), height2 = height - mean(height)) %>%
mutate(age3 = scale(age), height3 = scale(height))
kids %>%
ggplot(aes(age3, height3))+
geom_point()
kids %>%
select(age, height) %>%
prcomp()
prcomp
library("FactoMineR")
PCA
kids %>%
select(age, height) %>%
prcomp() -> res
res
names(res)
?prcomp
kids %>%
select(age, height) %>%
prcomp(center=F) -> res
(kids %>%
select(age, height) %>%
prcomp(center=F) -> res)
(kids %>%
select(age, height) %>%
prcomp(center=T) -> res)
(kids %>%
select(age, height) %>%
prcomp(center=T, scale. = T) -> res)
(kids %>%
select(age, height) %>%
PCA())
(kids %>%
select(age, height) %>%
PCA() -> res2)
res
names(res)
res$sdev
res$rotation
res$center
kids %>% summarise(mean(age), mean(height))
res$scale
res$x
kids
kids %>%
mutate((age - mean(age))/sd(age))
kids %>%
mutate((age - mean(age))/sd(age), scale(age))
kids %>%
mutate((age - mean(age))/sd(age), scale(age))
kids %>%
cor(.$age, .$height)
kids %>%
select(age, height) %>%
cov()
kids
kids %>%
select(age, height) %>%
mutate(age =scale(age), height = scale(height)) %>%
cov()
cor(scale(kids$age), scale(kids$height))
thesum <- 1.284028 + .04908323
1.284028/thesum
.04908323/thesum
eigen
cor(scale(kids$age), scale(kids$height))
kids %>%
select(age, height) %>%
mutate(age =scale(age), height = scale(height)) %>%
cov()
covariance_matrix <- kids %>%
select(age, height) %>%
mutate(age =scale(age), height = scale(height)) %>%
cov()
eigen(covariance_matrix)
eigen
res
matrix(c(7, 3, 3, -1), nrow = 2, byrow = T)
matrix(c(7, 3, 3, -1), nrow = 2, byrow = T) %>%
cov()
(matrix(c(7, 3, 3, -1), nrow = 2, byrow = T) %>%
prcomp() -> asdf)
library(Rling)
data("reg_bnc")
view(reg_bnc)
?reg_bnc
reg_bnc %>% select(Ncomm:Num)
reg_bnc %>% select(Ncomm:Num) %>% as_tibble()
reg_bnc %>% select(Ncomm:Num) %>% as_tibble() %>% slice(1)
reg_bnc %>% select(Ncomm:Num) %>% as_tibble() %>% slice(1) %>% sum()
reg_bnc %>% count(Reg)
clear
clear()
eigenvalues <- c(5.068, 1.87, 1.376, .79, .645, .422)
sum(eigenvalues)
eigenvalues / sum(eigenvalues)
eigenvalues <- c(5.0682936, 1.87221, 1.3758435, .79007, .645127, .421714)
eigenvalues / sum(eigenvalues)
sessionInfo()
reg_bnc
reg_bnc %>% names
install.packages("factoextra")
install.packages("corrplot")
suppressPackageStartupMessages(library("tidyverse"))
# helper function 1, for vowel words
trans_v <-  function(wd, vowels) {
return(str_c(wd, "yay"))
}
# helper function 2, for consonant words
trans_c <- function(wd, vowels, first_let) {
second_let <- str_sub(wd, 2, 2)
if (!str_to_lower(second_let) %in% vowels) {
first_two <- str_sub(wd, 1, 2)
rest_wd <- str_sub(wd, 3, str_length(wd))
return(str_c(rest_wd, first_two, "ay"))
} else {
rest_wd <- str_sub(wd, 2, str_length(wd))
return(str_c(rest_wd, first_let, "ay"))
}
}
# the main function
trans_pig <- function(sentence, vowels) {
wds <- unlist(str_split(sentence, "\\s+"))
trans_sent <- ""
for (wd in wds) {
first_let <- str_sub(wd, 1, 1)
if (str_to_lower(first_let) %in% vowels) {
# this is a vowel word
trans_sent <- str_c(trans_sent, trans_v(wd, vowels), " ")
} else {
# the current word is a consonant word
trans_sent <- str_c(trans_sent, trans_c(wd, vowels, first_let), " ")
}
}
return(str_trim(trans_sent))
}
### test the function
sentence <- "I do not like green eggs and ham."
vowels <- c("a", "e", "i", "o", "u")
print(trans_pig(sentence, vowels))
install.packages("rio")
library("rio")
install.packages("arrow")
students <- c("Joy", "Hernan")
grades <- c(90, 80)
assign_grades <- function(in_number) {
if (in_number >= 90) {
return("A")
} else if (in_number >= 80) {
return("B")
}
}
for (current_score in grades) {
assign_grades((current_score))
}
for (current_score in grades) {
print(assign_grades((current_score)))
}
library("tidyverse")
library("rvest")
"https://en.wikipedia.org/wiki/World_Chess_Championship" %>%  # put URL in a string
read_html() %>%  # request page
html_elements("table") %>%  # find all "table" HTML elements; mind the plural "html_elements"
.[2] %>%
html_table(header = TRUE) %>%  # convert HTML table to data frame (i.e., tibble)
print()
"https://en.wikipedia.org/wiki/World_Chess_Championship" %>%  # put URL in a string
read_html() %>%  # request page
html_elements("table") %>%  # find all "table" HTML elements; mind the plural "html_elements"
.[6] %>%
html_table(header = TRUE) %>%  # convert HTML table to data frame (i.e., tibble)
print()
install.packages("nycflights13", repos = "https://cran.rstudio.com")
flights |>
filter(arr_delay >= 120)
library("nycflights13")
library("tidyverse")
flights |>
filter(arr_delay >= 120)
flights |>
filter(dest %in% c("IAH", "HOU"))
install.packages("remotes")
remotes::install_github("joeystanley/joeysvowels")
library("tidyverse")
?stat_summary
library("reticulate")
use_python("/usr/local/bin/python3")
txt <- "The quick brown fox jumped over the lazy dog."
nltk <- import("nltk")
nltk <- import("nltk")
tokens <- nltk$word_tokenize(txt)
library("reticulate")
use_python("/usr/local/bin/python3")
txt <- "The quick brown fox jumped over the lazy dog."
nltk <- import("nltk")
tokens <- nltk$word_tokenize(txt)
print(tokens)
tagged <- nltk$pos_tag(tokens)
use_python("/usr/local/bin/python3")
txt
nltk <- import("nltk")
tokens <- nltk$word_tokenize(txt)
tokens
tagged <- nltk$pos_tag(tokens)
tagged <- nltk$pos_tag(tokens)
tagged
f
library("Rcpp")
cppFunction('int add(int x, int y, int z) {
int sum = x + y + z;
return sum;
}')
add(1, 2, 3)
install.packages("JuliaCall", repos = "http://cran.rstudio.com/")
println("hello Julia!")
install.packages("JuliaCall", repos = "http://cran.rstudio.com/")
install_julia()
library("JuliaCall")
install_julia()
julia <- julia_setup()
# R code here
library("reticulate")
install.packages("reticulate")
# R code here
library("reticulate")
use_python("/usr/local/bin/python3")
txt <- "The quick brown fox jumped over the lazy dog."
nltk <- import("nltk")
nltk$download("punkt")
nltk$download("averaged_perceptron_tagger")
tokens <- nltk$word_tokenize(txt)
print(tokens)
txt <- "The quick brown fox jumped over the lazy dog. I'm from the U.S.A and I am Mr. Brown?"
nltk <- import("nltk")
tokens <- nltk$word_tokenize(txt)
print(tokens)
txt <- "The quick brown fox jumped over the lazy dog. I'm from the U.S.A. and I am Mr. Brown?"
tokens <- nltk$word_tokenize(txt)
print(tokens)
tagged <- nltk$pos_tag(tokens)
print(tagged)
class(tagged)
library(reticulate)
txt <- "The quick brown fox jumped over the lazy dog."
nltk <- import("nltk")
nltk <- import("nltk")
py_require("nltk")
nltk <- import("nltk")
txt
tokens <- nltk$word_tokenize(txt)
tokens
tagged <- nltk$pos_tag(tokens)
tagged
reticulate::repl_python()
print("asdf")
library("reticulate")
py_require("num2words")
num2words=import("num2words")
num2words$num2words(4)
py_config()
#| eval: true
library("reticulate")
py_require("num2words")
num2words <- import("num2words")
num_as_word <- num2words$num2words(4)
print(num_as_word)
py_require("nltk")
nltk <- import("nltk")
num_as_word
#| eval: true
library("reticulate")
py_require("num2words")
num2words <- import("num2words")
asdf <- num2words$num2words(4)
print(asdf)
asdf
install.packages("languageR")
library("languageR")
data(ratings)
force(ratings)
install.packages("languageR"); library("languageR"); data(ratings)
ratings
dim(ratings)
ratings$meanFamiliarity
install.packages("Rling")
install.packages("lmerTest")
